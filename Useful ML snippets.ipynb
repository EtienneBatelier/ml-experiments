{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7db08b0-a3fc-4532-8ea8-c14884ba9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This functions creates two popular plots for quickly visualizing a model and trying to spot patterns in places where the fit is not great. \n",
    "#The plots are true responses vs. predictions and residuals vs. predictions. \n",
    "#y is assumed to be a DataFrame and predictions a numpy array (common sklearn setup). \n",
    "\n",
    "def plot_pred_res(predictions, y, size = .5): \n",
    "    pred_tmp = predictions\n",
    "    if len(predictions.shape) > 1:\n",
    "        pred_tmp = predictions[:, 0]\n",
    "    residuals = np.array(y[y.columns[0]]) - pred_tmp\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (8, 4))\n",
    "    ax[0].set_xlabel('Response')\n",
    "    ax[0].set_ylabel('Predictions')\n",
    "    ax[0].scatter(y, pred_tmp, s = size)\n",
    "    ax[0].plot([y[y.columns[0]].min(), y[y.columns[0]].max()], [y[y.columns[0]].min(), y[y.columns[0]].max()], color = 'red', linestyle = '--')\n",
    "    ax[1].set_xlabel('Predictions')\n",
    "    ax[1].set_ylabel('Residuals')\n",
    "    ax[1].scatter(pred_tmp, residuals, s = size)\n",
    "    ax[1].plot([predictions.min(), predictions.max()], residuals.mean().mean()*np.ones(2), color = 'red', linestyle = '--')\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f7aa2f-bc64-4c78-a81d-d1842a5444ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function estimates the variance of an estimator func, using data from a DataFrame df. \n",
    "#The function func is assumed to take as input a DataFrame. \n",
    "#It applies a bootstrap approach. \n",
    "\n",
    "def boot_var(func, df, n=None, B=1000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or df.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(df.index, n, replace=True)\n",
    "        value = func(df.loc[idx])\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return second_ / B - (first_ / B)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f5e4f7-54ac-4ebf-8ca7-68c36e998713",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 6 (220186999.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    def fit(self, X=None, y=None):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 6\n"
     ]
    }
   ],
   "source": [
    "#The empty template for creating a custom sklearn transformer. \n",
    "#It is nice to use the same signature for the fit and transform function \n",
    "#(using default None values if needed), for this enables the fit_transform() method. \n",
    "\n",
    "class DistanceToCities(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self): #If one needs to set attributes when summoning an instance of the transformer, they should be passed here. \n",
    "        \n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None): \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5acb0763-9a56-470f-b660-30fe88119d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(estimator, X, y): #\n",
    "    #The estimator is an sklearn estimator. It is assumed to be already fit. \n",
    "    #y is assumed to be a DataFrame with a single column: the observed response. \n",
    "    #The if blocks are only here to adapt to the many possible formats for estimator.predict(X). \n",
    "    yhat = estimator.predict(X)\n",
    "    if len(yhat.shape) == 1: \n",
    "        return ((np.array(y[y.columns[0]]) - yhat)**2).mean(0)\n",
    "    if yhat.shape[1] != 1:\n",
    "        return (([value*np.ones(yhat.shape[1]) for value in np.array(y[y.columns[0]])] - yhat)**2).mean(0)\n",
    "    return ((np.array(y[y.columns[0]]) - yhat[:, 0])**2).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338174ee-a764-41ec-88d3-a3d2219ca49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_CV(estimator, X, y): \n",
    "    #The estimator is an sklearn estimator. It is assumed to be already fit. \n",
    "    #y is assumed to be a DataFrame with a single column: the observed response. \n",
    "    K = 8\n",
    "    kfold_cv = sklms.KFold(K, random_state=0, shuffle=True)\n",
    "    predictions_cv = sklms.cross_val_predict(estimator, X, y, cv=kfold_cv) \n",
    "    MSE_cv = []\n",
    "    for train_idx, test_idx in kfold_cv.split(y):\n",
    "        MSE_values = ((np.array(y_df[y.columns[0]])[test_idx, None] - predictions_cv[test_idx])**2).mean(0)\n",
    "        MSE_cv.append(MSE_values) # column means\n",
    "    return np.array(MSE_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e61ae1-bca1-44d4-892c-b49a17338002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
